{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import omegaconf\n",
    "\n",
    "import mbrl.env.cartpole_continuous as cartpole_env\n",
    "import mbrl.env.reward_fns as reward_fns\n",
    "import mbrl.env.termination_fns as termination_fns\n",
    "import mbrl.models as models\n",
    "import mbrl.planning as planning\n",
    "import mbrl.util.common as common_util\n",
    "import mbrl.util as util\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "mpl.rcParams.update({\"font.size\": 16})\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "env = cartpole_env.CartPoleEnv()\n",
    "env.seed(seed)\n",
    "rng = np.random.default_rng(seed=0)\n",
    "generator = torch.Generator(device=device)\n",
    "generator.manual_seed(seed)\n",
    "obs_shape = env.observation_space.shape\n",
    "act_shape = env.action_space.shape\n",
    "\n",
    "# This functions allows the model to evaluate the true rewards given an observation \n",
    "reward_fn = reward_fns.cartpole\n",
    "# This function allows the model to know if an observation should make the episode end\n",
    "term_fn = termination_fns.cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_length = 20\n",
    "num_trials = 10\n",
    "ensemble_size = 2\n",
    "\n",
    "# Everything with \"???\" indicates an option with a missing value.\n",
    "# Our utility functions will fill in these details using the \n",
    "# environment information\n",
    "cfg_dict = {\n",
    "    # dynamics model configuration\n",
    "    \"dynamics_model\": {\n",
    "        # \"_target_\": \"mbrl.models.GaussianMLP\",\n",
    "        \"_target_\": \"Models.BNN.BNN\",\n",
    "        \"device\": device,\n",
    "        \"num_layers\": 2,\n",
    "        \"ensemble_size\": ensemble_size,\n",
    "        \"hid_size\": 10,\n",
    "        \"in_size\": \"???\",\n",
    "        \"out_size\": \"???\",\n",
    "        \"deterministic\": True,\n",
    "        \"propagation_method\": \"fixed_model\",\n",
    "        # can also configure activation function for GaussianMLP\n",
    "        \"activation_fn_cfg\": {\n",
    "            \"_target_\": \"torch.nn.LeakyReLU\",\n",
    "            \"negative_slope\": 0.01\n",
    "        }\n",
    "    },\n",
    "    # options for training the dynamics model\n",
    "    \"algorithm\": {\n",
    "        \"learned_rewards\": False,\n",
    "        \"target_is_delta\": True,\n",
    "        \"normalize\": True,\n",
    "    },\n",
    "    # these are experiment specific options\n",
    "    \"overrides\": {\n",
    "        \"trial_length\": trial_length,\n",
    "        \"num_steps\": num_trials * trial_length,\n",
    "        \"model_batch_size\": 32,\n",
    "        \"validation_ratio\": 0.05\n",
    "    }\n",
    "}\n",
    "cfg = omegaconf.OmegaConf.create(cfg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 1-D dynamics model for this environment\n",
    "dynamics_model = common_util.create_one_dim_tr_model(cfg, obs_shape, act_shape)\n",
    "\n",
    "# Create a gym-like environment to encapsulate the model\n",
    "model_env = models.ModelEnv(env, dynamics_model, term_fn, reward_fn, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = common_util.create_replay_buffer(cfg, obs_shape, act_shape, rng=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples stored 20\n"
     ]
    }
   ],
   "source": [
    "common_util.rollout_agent_trajectories(\n",
    "    env,\n",
    "    trial_length, # initial exploration steps\n",
    "    planning.RandomAgent(env),\n",
    "    {}, # keyword arguments to pass to agent.act()\n",
    "    replay_buffer=replay_buffer,\n",
    "    trial_length=trial_length\n",
    ")\n",
    "\n",
    "print(\"# samples stored\", replay_buffer.num_stored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_cfg = omegaconf.OmegaConf.create({\n",
    "    # this class evaluates many trajectories and picks the best one\n",
    "    \"_target_\": \"mbrl.planning.TrajectoryOptimizerAgent\",\n",
    "    \"planning_horizon\": 15,\n",
    "    \"replan_freq\": 1,\n",
    "    \"verbose\": False,\n",
    "    \"action_lb\": \"???\",\n",
    "    \"action_ub\": \"???\",\n",
    "    # this is the optimizer to generate and choose a trajectory\n",
    "    \"optimizer_cfg\": {\n",
    "        \"_target_\": \"mbrl.planning.CEMOptimizer\",\n",
    "        \"num_iterations\": 5,\n",
    "        \"elite_ratio\": 0.1,\n",
    "        \"population_size\": 500,\n",
    "        \"alpha\": 0.1,\n",
    "        \"device\": device,\n",
    "        \"lower_bound\": \"???\",\n",
    "        \"upper_bound\": \"???\",\n",
    "        \"return_mean_elites\": True,\n",
    "        \"clipped_normal\": False\n",
    "    }\n",
    "})\n",
    "\n",
    "agent = planning.create_trajectory_optim_agent_for_model(\n",
    "    model_env,\n",
    "    agent_cfg,\n",
    "    num_particles=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_scores = []\n",
    "\n",
    "def train_callback(_model, _total_calls, _epoch, tr_loss, val_score, _best_val):\n",
    "    train_losses.append(tr_loss)\n",
    "    val_scores.append(val_score.mean().item())   # this returns val score per ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_axes(_axs, _frame, _text, _trial, _steps_trial, _all_rewards, force_update=False):\n",
    "    if not force_update and (_steps_trial % 10 != 0):\n",
    "        return\n",
    "    _axs[0].imshow(_frame)\n",
    "    _axs[0].set_xticks([])\n",
    "    _axs[0].set_yticks([])\n",
    "    _axs[1].clear()\n",
    "    _axs[1].set_xlim([0, num_trials + .1])\n",
    "    _axs[1].set_ylim([0, 200])\n",
    "    _axs[1].set_xlabel(\"Trial\")\n",
    "    _axs[1].set_ylabel(\"Trial reward\")\n",
    "    _axs[1].plot(_all_rewards, 'bs-')\n",
    "    _text.set_text(f\"Trial {_trial + 1}: {_steps_trial} steps\")\n",
    "    display.display(plt.gcf())  \n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kveen\\OneDrive\\NTNU\\Project\\Models\\BNN.py:375: UserWarning: Using a target size (torch.Size([3, 1, 4])) that is different to the input size (torch.Size([3, 3, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(pred_mean, target, reduction=\"none\"), {}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "To use GaussianMLP's ensemble propagation, the batch size [10000] must be a multiple of the number of models [3] in the ensemble.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-52dc08004aca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;31m# --- Doing env step using the agent and adding to model dataset ---\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         next_obs, reward, done, _ = common_util.step_env_and_add_to_buffer(\n\u001b[0m\u001b[0;32m     44\u001b[0m             env, obs, agent, {}, replay_buffer)\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kveen\\onedrive\\ntnu\\mbrl-lib\\mbrl\\util\\common.py\u001b[0m in \u001b[0;36mstep_env_and_add_to_buffer\u001b[1;34m(env, obs, agent, agent_kwargs, replay_buffer, callback, agent_uses_low_dim_obs)\u001b[0m\n\u001b[0;32m    597\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[0magent_obs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m     \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0magent_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[0mnext_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[0mreplay_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kveen\\onedrive\\ntnu\\mbrl-lib\\mbrl\\planning\\trajectory_opt.py\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, obs, optimizer_callback, **_kwargs)\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 684\u001b[1;33m             plan = self.optimizer.optimize(\n\u001b[0m\u001b[0;32m    685\u001b[0m                 \u001b[0mtrajectory_eval_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer_callback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m             )\n",
      "\u001b[1;32mc:\\users\\kveen\\onedrive\\ntnu\\mbrl-lib\\mbrl\\planning\\trajectory_opt.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, trajectory_eval_fn, callback)\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m \u001b[0mof\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbest\u001b[0m \u001b[0maction\u001b[0m \u001b[0msequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m         \"\"\"\n\u001b[1;32m--> 558\u001b[1;33m         best_solution = self.optimizer.optimize(\n\u001b[0m\u001b[0;32m    559\u001b[0m             \u001b[0mtrajectory_eval_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m             \u001b[0mx0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprevious_solution\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kveen\\onedrive\\ntnu\\mbrl-lib\\mbrl\\planning\\trajectory_opt.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, obj_fun, x0, callback, **kwargs)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[0mpopulation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sample_population\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdispersion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kveen\\onedrive\\ntnu\\mbrl-lib\\mbrl\\planning\\trajectory_opt.py\u001b[0m in \u001b[0;36mtrajectory_eval_fn\u001b[1;34m(action_sequences)\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mtrajectory_eval_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_sequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrajectory_eval_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_sequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kveen\\onedrive\\ntnu\\mbrl-lib\\mbrl\\planning\\trajectory_opt.py\u001b[0m in \u001b[0;36mtrajectory_eval_fn\u001b[1;34m(initial_state, action_sequences)\u001b[0m\n\u001b[0;32m    742\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrajectory_eval_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_sequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m         return model_env.evaluate_action_sequences(\n\u001b[0m\u001b[0;32m    745\u001b[0m             \u001b[0maction_sequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_particles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m         )\n",
      "\u001b[1;32mc:\\users\\kveen\\onedrive\\ntnu\\mbrl-lib\\mbrl\\models\\model_env.py\u001b[0m in \u001b[0;36mevaluate_action_sequences\u001b[1;34m(self, action_sequences, initial_state, num_particles)\u001b[0m\n\u001b[0;32m    172\u001b[0m             )\n\u001b[0;32m    173\u001b[0m             \u001b[0minitial_obs_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtiling_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             \u001b[0mmodel_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_obs_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_as_np\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitial_obs_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mtotal_rewards\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kveen\\onedrive\\ntnu\\mbrl-lib\\mbrl\\models\\model_env.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self, initial_obs_batch, return_as_np)\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_obs_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m  \u001b[1;31m# batch, obs_dim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             model_state = self.dynamics_model.reset(\n\u001b[0m\u001b[0;32m     82\u001b[0m                 \u001b[0minitial_obs_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             )\n",
      "\u001b[1;32mc:\\users\\kveen\\onedrive\\ntnu\\mbrl-lib\\mbrl\\models\\one_dim_tr_model.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self, obs, rng)\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[0mmodel_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"obs\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m         \u001b[0mmodel_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kveen\\onedrive\\ntnu\\mbrl-lib\\mbrl\\models\\model.py\u001b[0m in \u001b[0;36mreset_1d\u001b[1;34m(self, obs, rng)\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mrng\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpropagation_method\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"fixed_model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m             \u001b[0mpropagation_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_propagation_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m             \u001b[0mpropagation_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kveen\\OneDrive\\NTNU\\Project\\Models\\BNN.py\u001b[0m in \u001b[0;36msample_propagation_indices\u001b[1;34m(self, batch_size, _rng)\u001b[0m\n\u001b[0;32m    382\u001b[0m         )\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmodel_len\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    385\u001b[0m                 \u001b[1;34mf\"To use GaussianMLP's ensemble propagation, the batch size [{batch_size}] must \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m                 \u001b[1;34mf\"be a multiple of the number of models [{model_len}] in the ensemble.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: To use GaussianMLP's ensemble propagation, the batch size [10000] must be a multiple of the number of models [3] in the ensemble."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x270 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a trainer for the model\n",
    "model_trainer = models.ModelTrainer(dynamics_model, optim_lr=1e-3, weight_decay=5e-5)\n",
    "\n",
    "# Create visualization objects\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 3.75), gridspec_kw={\"width_ratios\": [1, 1]})\n",
    "ax_text = axs[0].text(300, 50, \"\")\n",
    "    \n",
    "# Main PETS loop\n",
    "all_rewards = [0]\n",
    "for trial in range(num_trials):\n",
    "    obs = env.reset()    \n",
    "    agent.reset()\n",
    "    \n",
    "    done = False\n",
    "    total_reward = 0.0\n",
    "    steps_trial = 0\n",
    "    update_axes(axs, env.render(mode=\"rgb_array\"), ax_text, trial, steps_trial, all_rewards)\n",
    "    while not done:\n",
    "        # --------------- Model Training -----------------\n",
    "        if steps_trial == 0:\n",
    "            dynamics_model.update_normalizer(replay_buffer.get_all())  # update normalizer stats\n",
    "            \n",
    "            dataset_train, dataset_val = common_util.get_basic_buffer_iterators(\n",
    "                replay_buffer,\n",
    "                batch_size=cfg.overrides.model_batch_size,\n",
    "                val_ratio=cfg.overrides.validation_ratio,\n",
    "                ensemble_size=ensemble_size,\n",
    "                shuffle_each_epoch=True,\n",
    "                bootstrap_permutes=False,  # build bootstrap dataset using sampling with replacement\n",
    "            )\n",
    "            # print(dataset_val.batch_size)\n",
    "            # print(dataset_val.ensemble_size)\n",
    "            # print(dataset_val.transitions)\n",
    "            model_trainer.train(\n",
    "                dataset_train, \n",
    "                dataset_val=dataset_val, \n",
    "                num_epochs=50, \n",
    "                patience=50, \n",
    "                callback=train_callback,\n",
    "                silent=True)\n",
    "\n",
    "        # --- Doing env step using the agent and adding to model dataset ---\n",
    "        next_obs, reward, done, _ = common_util.step_env_and_add_to_buffer(\n",
    "            env, obs, agent, {}, replay_buffer)\n",
    "            \n",
    "        update_axes(\n",
    "            axs, env.render(mode=\"rgb_array\"), ax_text, trial, steps_trial, all_rewards)\n",
    "        \n",
    "        obs = next_obs\n",
    "        total_reward += reward\n",
    "        steps_trial += 1\n",
    "        \n",
    "        if steps_trial == trial_length:\n",
    "            break\n",
    "    \n",
    "    all_rewards.append(total_reward)\n",
    "\n",
    "update_axes(axs, env.render(mode=\"rgb_array\"), ax_text, trial, steps_trial, all_rewards, force_update=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(12, 10))\n",
    "ax[0].plot(train_losses)\n",
    "ax[0].set_xlabel(\"Total training epochs\")\n",
    "ax[0].set_ylabel(\"Training loss (avg. NLL)\")\n",
    "ax[1].plot(val_scores)\n",
    "ax[1].set_xlabel(\"Total training epochs\")\n",
    "ax[1].set_ylabel(\"Validation score (avg. MSE)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ceeec6f9b5be10503b0796aea8d227cb1e3fcd6473678523bae4aae3896c265d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
